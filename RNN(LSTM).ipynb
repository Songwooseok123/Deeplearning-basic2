{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "밑바닥2-6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5qFss6dqryrqc35e7lLcK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Songwooseok123/Deeplearning-basic2/blob/main/RNN(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVg12ZCQFyB_"
      },
      "source": [
        "#게이트가 추가된 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP_sI643F3pG"
      },
      "source": [
        "rnn의 문제점\n",
        "- 시계열 데이터의 장기 의존 관계를 학습하기 어려움(BPTT에서 기울기 소실 혹은 폭발이 일어남.)\n",
        "->게이트가 추가된 rnn : LSTM, GRU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g25dubjIaE4"
      },
      "source": [
        "기울기 폭발 해결- 기울기 클리핑 : threshold를 설정. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-A08DxyIp7z"
      },
      "source": [
        "import numpy as np\n",
        "dw1=np.random.rand(3,3)*10\n",
        "dw2=np.random.rand(3,3)*10\n",
        "grads=[dw1,dw2]\n",
        "max_norm=5.0 #threshold\n",
        "\n",
        "def clip_grads(grads,max_norm):\n",
        "  total_norm = 0\n",
        "  for grads in grads:\n",
        "    total_norm +=np.sum(grad**2)\n",
        "  total_norm=np.sqrt(total_norm)\n",
        "  rate=max_norm/(total_norm +1e-6)\n",
        "  if rate<1:\n",
        "    for grad in grads:\n",
        "      grad*=rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5rVSwxIJkGZ"
      },
      "source": [
        "## 기울기 소실 해결 -LSTM\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5ylPuYwJavL"
      },
      "source": [
        "class BetterRnnlm(BaseModel):\n",
        "    '''\n",
        "     LSTM 계층을 2개 사용하고 각 층에 드롭아웃을 적용한 모델이다.\n",
        "     아래 [1]에서 제안한 모델을 기초로 하였고, [2]와 [3]의 가중치 공유(weight tying)를 적용했다.\n",
        "     [1] Recurrent Neural Network Regularization (https://arxiv.org/abs/1409.2329)\n",
        "     [2] Using the Output Embedding to Improve Language Models (https://arxiv.org/abs/1608.05859)\n",
        "     [3] Tying Word Vectors and Word Classifiers (https://arxiv.org/pdf/1611.01462.pdf)\n",
        "    '''\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
        "                 hidden_size=650, dropout_ratio=0.5):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
        "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs, train_flg=False):\n",
        "        for layer in self.drop_layers:\n",
        "            layer.train_flg = train_flg\n",
        "\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts, train_flg=True):\n",
        "        score = self.predict(xs, train_flg)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        for layer in self.lstm_layers:\n",
        "            layer.reset_state()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zE3mFC7o28t"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from common import config\n",
        "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
        "# ==============================================\n",
        "# config.GPU = True\n",
        "# ==============================================\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity, to_gpu\n",
        "from dataset import ptb\n",
        "from better_rnnlm import BetterRnnlm\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 20\n",
        "wordvec_size = 650\n",
        "hidden_size = 650\n",
        "time_size = 35\n",
        "lr = 20.0\n",
        "max_epoch = 40\n",
        "max_grad = 0.25\n",
        "dropout = 0.5\n",
        "\n",
        "# 학습 데이터 읽기\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_val, _, _ = ptb.load_data('val')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "\n",
        "if config.GPU:\n",
        "    corpus = to_gpu(corpus)\n",
        "    corpus_val = to_gpu(corpus_val)\n",
        "    corpus_test = to_gpu(corpus_test)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "best_ppl = float('inf')\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
        "                time_size=time_size, max_grad=max_grad)\n",
        "\n",
        "    model.reset_state()\n",
        "    ppl = eval_perplexity(model, corpus_val)\n",
        "    print('검증 퍼플렉서티: ', ppl)\n",
        "\n",
        "    if best_ppl > ppl:\n",
        "        best_ppl = ppl\n",
        "        model.save_params()\n",
        "    else:\n",
        "        lr /= 4.0\n",
        "        optimizer.lr = lr\n",
        "\n",
        "    model.reset_state()\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.reset_state()\n",
        "ppl_test = eval_perplexity(model, corpus_test)\n",
        "print('테스트 퍼플렉서티: ', ppl_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}